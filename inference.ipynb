{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrkAxQOUkkJA"
   },
   "source": [
    "# First, some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "kUX6_56tDC1A"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 23:19:40.894068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import functools\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jaxline\n",
    "import note_seq\n",
    "from typing import Generator, Mapping, Sequence, Text\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import haiku as hk\n",
    "import IPython\n",
    "from PIL import Image\n",
    "import datetime\n",
    "\n",
    "import experiment\n",
    "import perceiver_ar\n",
    "import dataset\n",
    "import sample_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "6mwtK9QqiZy2"
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO_GI8OoCz43"
   },
   "source": [
    "# Restore a full experiment from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modality = 'raw'\n",
    "# sweep_name = 'random_mirrored_32'\n",
    "# checkpoint_base = Path('/tmp/perceiver_ar')\n",
    "\n",
    "# modality = 'raw'\n",
    "# sweep_name = 'random_mirrored_131072'\n",
    "# checkpoint_base = Path('/tmp/perceiver_ar_pretrained_checkpoints/random_mirrored_131072')\n",
    "\n",
    "modality = 'image_w_positions'\n",
    "sweep_name = 'imagenet_w_positions'\n",
    "checkpoint_base = Path('/tmp/perceiver_ar_pretrained_checkpoints/imagenet_w_positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "DC_0lmzQiefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be loaded from: /tmp/perceiver_ar_pretrained_checkpoints/imagenet_w_positions/models/latest/step_750000\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = sorted((checkpoint_base / 'models/latest').iterdir(), key=lambda x: x.stat().st_mtime)[-1]\n",
    "\n",
    "print(f'Model will be loaded from: {checkpoint_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "config = experiment.get_config(sweep_name)\n",
    "experiment.restore_state_to_in_memory_checkpointer(checkpoint_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "DYI4md87D4l2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored step 750000\n"
     ]
    }
   ],
   "source": [
    "checkpointer = jaxline.platform.create_checkpointer(config, 'eval')\n",
    "state = checkpointer.get_experiment_state('latest')\n",
    "\n",
    "# Add the fields you want to restore here.\n",
    "# Must include experiment_module.\n",
    "state.global_step = 0\n",
    "state.experiment_module = experiment.Experiment(\n",
    "    'eval', jax.random.PRNGKey(config.random_seed),\n",
    "    **config.experiment_kwargs)\n",
    "\n",
    "checkpointer.restore('latest')\n",
    "exp_params = jaxline.utils.get_first(state.experiment_module._params)\n",
    "exp_state = jaxline.utils.get_first(state.experiment_module._state)\n",
    "\n",
    "max_context_length = config.experiment_kwargs.config.data.max_context_length\n",
    "# We want to store max_context_length plus the final prediction.\n",
    "max_events_length = max_context_length + 1\n",
    "\n",
    "events = np.zeros([1, max_events_length], np.int32)\n",
    "events[:, 0] = dataset.SOS_ID\n",
    "\n",
    "print('Restored step', state.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w9G_ZD-kHQS"
   },
   "source": [
    "# Now run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "id": "a14UJG7q6Qif"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device count 1\n"
     ]
    }
   ],
   "source": [
    "#@title Set up the input sequence (NB: start_step ignored for some init types)\n",
    "\n",
    "batch_size =   1#@param {type:\"integer\"}\n",
    "input_sequence_init = 'zeros'  #@param ['zeros', 'mirror_input'] {type:\"string\"}\n",
    "start_step = 1#@param {type:\"integer\"}\n",
    "\n",
    "device_count = jax.local_device_count()\n",
    "print('device count', device_count)\n",
    "\n",
    "max_context_length = config.experiment_kwargs.config.data.max_context_length\n",
    "# We want to store max_context_length plus the final prediction.\n",
    "max_events_length = max_context_length + 1\n",
    "\n",
    "if input_sequence_init == 'zeros':\n",
    "  def gen_initial_events():\n",
    "    events = np.zeros([device_count, batch_size, max_events_length], np.int32)\n",
    "    # Add expected SOS prompt.\n",
    "    events[:, :, 0] = dataset.SOS_ID\n",
    "    return events\n",
    "elif input_sequence_init == 'mirror_input':\n",
    "  # Account for the SOS\n",
    "  seq_len = config.experiment_kwargs.config.data.max_context_length - 2\n",
    "  seq_len = seq_len // 2\n",
    "\n",
    "  start_step = seq_len + 1\n",
    "  print('Using input_sequence_init `mirror_input`. Setting '\n",
    "        f'start_step to {start_step}.')\n",
    "\n",
    "  def gen_initial_events():\n",
    "    # Initialize with a random MirroredDataset sequence.\n",
    "    events = np.zeros([device_count, batch_size, max_events_length], np.int32)\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    forward_sequence = jax.random.randint(\n",
    "        rng, [device_count, batch_size, seq_len], \n",
    "        minval=dataset.NUM_RESERVED_TOKENS, \n",
    "        maxval=256 + dataset.NUM_RESERVED_TOKENS, \n",
    "        dtype=jnp.int32)\n",
    "  \n",
    "    # Force start_step to half the sequence length:\n",
    "    events[:, :, 1:seq_len+1] = forward_sequence\n",
    "    # Add expected SOS prompt.\n",
    "    events[:, :, 0] = dataset.SOS_ID\n",
    "    return events\n",
    "\n",
    "if start_step < 1:\n",
    "  raise ValueError('start_step must be >= 1 to account for the SOS token.')\n",
    "\n",
    "# Make sure start_step doesn't exceed the maximum context of the model.\n",
    "if start_step > max_context_length:\n",
    "  print(f'Warning: start_step {start_step} exceeds '\n",
    "        f'max_context_length used at training {max_context_length}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "id": "1XO4kwRiX3Uy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default max_context_length for memory: 12416\n",
      "Using default z_index_dim for memory: 1024\n"
     ]
    }
   ],
   "source": [
    "#@title Memory parameters (set to 0 to use model defaults)\n",
    "use_memory = True #@param {type:\"boolean\"}\n",
    "max_context_length_memory = 0 #@param {type:\"integer\"}\n",
    "z_index_dim_memory =  0#@param {type: \"integer\"}\n",
    "\n",
    "model_kwargs = config.experiment_kwargs.config.model.perceiver_ar_kwargs\n",
    "# These values can be adjusted, but set to defaults if not specified\n",
    "if use_memory:\n",
    "  if max_context_length_memory == 0:\n",
    "    print('Using default max_context_length for memory: '\n",
    "          f'{config.max_context_length}')\n",
    "    max_context_length_memory = config.max_context_length\n",
    "  if z_index_dim_memory == 0:\n",
    "    print(f'Using default z_index_dim for memory: {model_kwargs.z_index_dim}')\n",
    "    z_index_dim_memory = model_kwargs.z_index_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "form",
    "id": "06cUc_uRL903"
   },
   "outputs": [],
   "source": [
    "#@title Set up sampling\n",
    "\n",
    "@functools.partial(jax.jit, static_argnums=(2, 3, 4, 5))\n",
    "def sample_sequences(\n",
    "    events, rng, \n",
    "    start_step=1, \n",
    "    num_steps=-1,\n",
    "    temperature=1.0, \n",
    "    top_p=1.0):\n",
    "  if num_steps < 0:\n",
    "    num_steps = events.shape[1] - start_step + 1\n",
    "\n",
    "  # Start at position 1 because SOS must be at position 0.\n",
    "  upper = min(num_steps + start_step, events.shape[1])\n",
    "  print('start_step', start_step)\n",
    "  print('upper', upper)\n",
    "\n",
    "  if modality == 'image_w_positions':\n",
    "    x_event_idxs = jnp.reshape(\n",
    "        jnp.broadcast_to(jnp.arange(64)[None, :, None] + 1, [64, 64, 3]), [-1])\n",
    "    y_event_idxs = jnp.reshape(\n",
    "        jnp.broadcast_to(jnp.arange(64)[:, None, None] + 1, [64, 64, 3]), [-1])\n",
    "    channel_event_idxs = jnp.reshape(\n",
    "        jnp.broadcast_to(jnp.array([1, 2, 3]), [64, 64, 3]), [-1])\n",
    "\n",
    "    event_idxs = jnp.stack(\n",
    "        [x_event_idxs, y_event_idxs, channel_event_idxs], axis=1)\n",
    "\n",
    "    # Account for SOS.\n",
    "    event_idxs = jnp.concatenate(\n",
    "        [jnp.ones([1, 3], dtype=jnp.int32), event_idxs + 1], axis=0)\n",
    "\n",
    "    # Pad remaining positions.\n",
    "    event_idxs = jnp.pad(\n",
    "        event_idxs, [[0, events.shape[1] - event_idxs.shape[0]], [0, 0]])\n",
    "\n",
    "    event_idxs = jnp.broadcast_to(event_idxs, events.shape + (3,))\n",
    "  else:\n",
    "    # Otherwise, assume linear event indices.\n",
    "    event_idxs = jnp.arange(start=1, stop=events.shape[1] + 1)\n",
    "    event_idxs = jnp.expand_dims(event_idxs, axis=-1)\n",
    "    event_idxs = jnp.broadcast_to(event_idxs, events.shape + (1,))\n",
    "  \n",
    "  model_kwargs = config.experiment_kwargs.config.model.perceiver_ar_kwargs\n",
    "\n",
    "  if use_memory:\n",
    "    # Zero-initialize the memory.\n",
    "    memory = sample_utils.initialize_memory(\n",
    "        batch_size=batch_size,\n",
    "        num_transformers_per_block=model_kwargs.num_transformers_per_block,\n",
    "        num_cross_attend_heads=model_kwargs.num_cross_attend_heads,\n",
    "        num_transformer_heads=model_kwargs.num_transformer_heads,\n",
    "        num_z_channels=model_kwargs.num_z_channels,\n",
    "        max_context_length_memory=max_context_length_memory,\n",
    "        z_index_dim_memory=z_index_dim_memory,\n",
    "        position_encoding_type=model_kwargs.position_encoding_type,\n",
    "        memory_type='fixed_size_kv')\n",
    "\n",
    "  # Build the parameters reused between model calls. \n",
    "  sample_position_args = dict(\n",
    "      event_idxs=event_idxs,\n",
    "      modality=modality,\n",
    "      temperature=temperature,\n",
    "      top_p=top_p,\n",
    "      use_memory=use_memory,\n",
    "  )\n",
    "\n",
    "  # Package the (constant) params and state with the model.\n",
    "  forward_fn = functools.partial(\n",
    "      state.experiment_module.forward.apply,\n",
    "      exp_params,\n",
    "      exp_state,\n",
    "  )\n",
    "\n",
    "  if use_memory and start_step > 1:\n",
    "    # Run forward the model with long context for one step to initialize \n",
    "    # the memory and get the first sample.\n",
    "    events, rng, memory = sample_utils.sample_position(\n",
    "        i=start_step,\n",
    "        events_rng_memory=(events, rng, memory),\n",
    "        forward_fn=forward_fn,\n",
    "        condition_on='all_previous',\n",
    "        **sample_position_args)\n",
    "    start_step += 1\n",
    "\n",
    "  if use_memory:\n",
    "    condition_on_loop = 'most_recent_only'\n",
    "  else:\n",
    "    condition_on_loop = 'all'\n",
    "  sample_positions_loop = functools.partial(\n",
    "      sample_utils.sample_position,\n",
    "      # i, events_rng_memory supplied by caller.\n",
    "      forward_fn=forward_fn,\n",
    "      condition_on=condition_on_loop,\n",
    "      **sample_position_args)\n",
    "\n",
    "  if use_memory:\n",
    "    inputs = (events, rng, memory)\n",
    "  else:\n",
    "    inputs = (events, rng)\n",
    "  \n",
    "  outputs = jax.lax.fori_loop(\n",
    "      start_step, upper, sample_positions_loop, inputs)\n",
    "  \n",
    "  return outputs\n",
    "\n",
    "sample_sequences = jax.pmap(\n",
    "    sample_sequences,\n",
    "    static_broadcasted_argnums=(2, 3, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "form",
    "id": "8tVZgwjfC3Hp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting generation 1653521802.615483\n",
      "start_step 1\n",
      "upper 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 23:40:13.851999: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:61] \n",
      "********************************\n",
      "Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "Compiling module pmap_sample_sequences.27\n",
      "********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation complete 1653522581.5779161\n",
      "778.9624330997467 seconds\n",
      "12.982707218329113 minutes\n"
     ]
    }
   ],
   "source": [
    "#@title Sample the sequence\n",
    "\n",
    "#@markdown `num_steps`=-1 will fill the entire buffer.\n",
    "num_steps =   -1#@param {type:\"integer\"}\n",
    "temperature =   1.0#@param {type:\"number\"}\n",
    "top_p =   1.0#@param {type:\"number\"}\n",
    "random_seed = 0#@param{type:\"integer\"}\n",
    "\n",
    "rng = jax.random.PRNGKey(random_seed)\n",
    "rng = jax.random.split(rng, device_count)\n",
    "\n",
    "events = gen_initial_events()\n",
    "\n",
    "if 'outputs' in locals():\n",
    "  del outputs\n",
    "if 'memory' in locals():\n",
    "  del memory\n",
    "if 'seq' in locals():\n",
    "  del seq\n",
    "\n",
    "tick = time.time()\n",
    "print('starting generation', tick)\n",
    "\n",
    "outputs = sample_sequences(\n",
    "    events, rng, start_step, num_steps, temperature, top_p)\n",
    "\n",
    "outputs = jax.tree_map(lambda x: x.block_until_ready(), outputs)\n",
    "tock = time.time()\n",
    "print('generation complete', tock)\n",
    "print(tock - tick, 'seconds')\n",
    "print((tock - tick) / 60, 'minutes')\n",
    "\n",
    "if use_memory:\n",
    "  events, rng, memory = outputs\n",
    "else:\n",
    "  events, rng = outputs\n",
    "\n",
    "# reshape to remove device axis\n",
    "events = events.reshape((np.prod(events.shape[:2]),) + events.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "id": "wozd0BFib6q8"
   },
   "outputs": [],
   "source": [
    "#@title Do the inputs and outputs of the mirrored_input test match?\n",
    "if input_sequence_init == 'mirror_input':\n",
    "  if num_steps < 0:\n",
    "    num_steps = events.shape[1] - start_step + 1\n",
    "\n",
    "  start_idx = max(start_step - num_steps, 0)\n",
    "  end_idx = min(start_step+num_steps, max_context_length) \n",
    "  last_inputs = events[:, start_idx:start_step][:, ::-1]\n",
    "  first_outputs = events[:, start_step:end_idx]\n",
    "  print(f'Last inputs (reversed):\\n {last_inputs}')\n",
    "  print(f'First outputs:\\n {first_outputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "b6bNeGfszNGE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No EOS token found.\n",
      "Found SOS at index 0 as expected, removing.\n",
      "Truncating 2 position(s) to ensure multiple of 3\n",
      "Truncating 42 tuple(s) to ensure multiple of 64\n",
      "-----\n",
      "(64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to /tmp/perceiver_ar_pretrained_checkpoints/imagenet_w_positions/inference/2022-05-25T234941.651172/im_0.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAAWklEQVR4nO3MMQqDUBAE0FmFEDXE+x8sbbpcw7X4HsAq1XswLMzA1u/7eT7WZXsvrz3TnH/okU6SGmc0xygrSbpTdQ1TclTmTip1PQAAAAAAAAAAAAAAAO46AYexD/qk4LRgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Visualize or play the sampled sequence\n",
    "\n",
    "inference_dir = checkpoint_base / 'inference' / datetime.datetime.now().isoformat().replace(\":\", \"\")\n",
    "im_timestamp = time.time()\n",
    "\n",
    "for i, seq in enumerate(events):\n",
    "  eos_idx = jnp.argmax(seq == dataset.EOS_ID)\n",
    "  if eos_idx:\n",
    "    print(f'Found EOS at index {eos_idx}, truncating.')\n",
    "    seq = seq[:eos_idx]\n",
    "  else:\n",
    "    print('No EOS token found.')\n",
    "\n",
    "  if seq[0] == dataset.SOS_ID:\n",
    "    print(f'Found SOS at index 0 as expected, removing.')\n",
    "    seq = seq[1:]\n",
    "  else:\n",
    "    print(f'WARNING: SOS not found at index 0. This should not happen.')\n",
    "\n",
    "  if modality in ['image', 'image_w_positions']:\n",
    "    seq = seq - dataset.NUM_RESERVED_TOKENS\n",
    "    rem = len(seq) % 3\n",
    "    if rem > 0:\n",
    "      print(f'Truncating {rem} position(s) to ensure multiple of 3')\n",
    "      seq = seq[:-rem]\n",
    "    seq = seq.reshape(-1, 3)\n",
    "    if modality == 'image':\n",
    "      seq -= jnp.broadcast_to([0, 256, 512], seq.shape)\n",
    "    rem = len(seq) % 64\n",
    "    if rem > 0:\n",
    "      print(f'Truncating {rem} tuple(s) to ensure multiple of 64')\n",
    "      seq = seq[:-rem]\n",
    "    seq = seq.reshape(-1, 64, 3)\n",
    "\n",
    "    seq = jnp.where(seq >= 0, seq, 0)\n",
    "    print('-----')\n",
    "    print(seq.shape)\n",
    "    plt.imshow(seq)\n",
    "    plt.show()\n",
    "\n",
    "    inference_dir.mkdir(parents=True, exist_ok=True)\n",
    "    im_filename = f'im_{i}.png'\n",
    "    im_path = inference_dir / im_filename\n",
    "    img = Image.fromarray(np.array(seq, dtype=np.uint8), mode='RGB')\n",
    "    print('saving to', im_path)\n",
    "    IPython.display.display(img)\n",
    "    img.save(im_path)\n",
    "  elif modality == 'raw':\n",
    "    print('Shape:', seq.shape)\n",
    "    print(seq)\n",
    "    print('#####')\n",
    "  else:\n",
    "    raise ValueError(f'Unknown modality: {modality}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
